{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7Aympk-qwGu"
   },
   "source": [
    "# Preliminaries: model definition and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFhWBUzvqmZF"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import *\n",
    "from utils import *\n",
    "from metrics import *\n",
    "from training_helpers import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5 # number of classes expert can predict\n",
    "n_dataset = 10\n",
    "Expert = synth_expert(k, n_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plcXrgr8q_dR"
   },
   "source": [
    "WideResNet from following [repo](https://github.com/xternalz/WideResNet-pytorch/blob/master/wideresnet.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUHnGa-M-GGA"
   },
   "source": [
    "# Active Learning Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxukz8OwMX7j"
   },
   "outputs": [],
   "source": [
    "use_data_aug = False # whether to use data augmentation, no for now\n",
    "n_dataset = 10  # cifar-10\n",
    "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                    std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "if use_data_aug:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: F.pad(x.unsqueeze(0),\n",
    "                                            (4, 4, 4, 4), mode='reflect').squeeze()),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "if n_dataset == 10:\n",
    "    dataset = 'cifar10'\n",
    "elif n_dataset == 100:\n",
    "    dataset = 'cifar100'\n",
    "\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "\n",
    "\n",
    "train_dataset_all = datasets.__dict__[dataset.upper()]('../data', train=True, download=True,\n",
    "                                                        transform=transform_train)\n",
    "train_size = int(0.90 * len(train_dataset_all)) # validation set\n",
    "test_size = len(train_dataset_all) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_all, [train_size, test_size])\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                           batch_size=128, shuffle=True, **kwargs)\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "#                                            batch_size=128, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "test_dataset = datasets.__dict__[\"cifar10\".upper()]('../data', train=False, transform=transform_test, download=True)\n",
    "#test_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.__dict__[\"cifar100\".upper()]('../data', train=False, transform=transform_test, download=True),\n",
    "#    batch_size=128, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWIHchCVWMP9"
   },
   "outputs": [],
   "source": [
    "dataset_train = CifarExpertDataset(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices))\n",
    "dataset_val = CifarExpertDataset(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices))\n",
    "dataset_test = CifarExpertDataset(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets))\n",
    "\n",
    "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8bHnx2qbN2o"
   },
   "source": [
    "# Optimal Solution\n",
    "Runs the L_{CE} method on the data with a simple neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuXS4uU7bRHC"
   },
   "outputs": [],
   "source": [
    "model = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "290EKr-kbWAR"
   },
   "outputs": [],
   "source": [
    "#run_reject(model, 10, Expert.predict, 70,0.5, dataLoaderTrain, dataLoaderVal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot1njxRujwn"
   },
   "source": [
    "# Active Learning\n",
    "The way I'm currently doing things is:\n",
    "- learn a classifier on all the data\n",
    "- initiate active learning parameters\n",
    "- run code for each active learning baseline and gather results\n",
    "- plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device) # classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBiX8F4sR1i1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_reject_class(model, 10, dataLoaderTrain, dataLoaderVal) # train classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkoMqa8o20mq"
   },
   "outputs": [],
   "source": [
    "metrics_print_classifier(model, dataLoaderVal) # show classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP7UruLjr2mQ"
   },
   "outputs": [],
   "source": [
    "# Active Learning parameters\n",
    "INITIAL_SIZE = 100 # initial size of data that has expert labels, randomly chosen\n",
    "BATCH_SIZE_AL = 1000 # batch size for acquisition of expert labels\n",
    "MAX_ROUNDS = 10 # how many rounds of expert queries: total size is initial_size + batch_size*max_rounds\n",
    "EPOCH_TRAIN = 10 # how many epochs to train after each acquistion\n",
    "MAX_TRIALS = 1 # repeat active learning for a number of trials to get error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1nvi-aKpREl"
   },
   "outputs": [],
   "source": [
    "# initiate data for active learning with labeled and unlabeled set\n",
    "all_indices = list(range(len(train_dataset.indices)))\n",
    "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
    "indices_labeled  = intial_random_set\n",
    "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
    "dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
    "\n",
    "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqo7eUnW5CHU"
   },
   "outputs": [],
   "source": [
    "Intial_random_set = random.sample(all_indices, INITIAL_SIZE) # initial random set is constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj4i8jVNZuWE"
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "error_random_trials = []\n",
    "for trial in range(MAX_TRIALS):\n",
    "    # repeat for each trial\n",
    "    print(f'\\n \\n \\n Trial {trial} \\n \\n \\n ')\n",
    "    all_indices = list(range(len(train_dataset.indices)))\n",
    "    all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "    all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
    "    dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
    "\n",
    "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "    # train expert model on initial labeled set\n",
    "    model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
    "    run_expert(model_expert, EPOCH_TRAIN, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "    data_sizes = []\n",
    "    error_random = []\n",
    "\n",
    "    data_sizes.append(INITIAL_SIZE)\n",
    "    metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
    "    error_random.append(metrics_random['system accuracy'])\n",
    "\n",
    "\n",
    "    for round in range(MAX_ROUNDS):\n",
    "        # in each round of active learning\n",
    "        # randomly sample data\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "        intial_random_set = random.sample(indices_unlabeled, BATCH_SIZE_AL) # sample random batch from unlabeled set\n",
    "        # create new datasets with new labeled data\n",
    "        indices_labeled  = indices_labeled + intial_random_set \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "        dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
    "        dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeledUnshuffled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "\n",
    "        # re-train expert model on new labeled data\n",
    "        run_expert(model_expert, EPOCH_TRAIN, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "        # get results of deferral and store them\n",
    "        metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderTest)\n",
    "        error_random.append(metrics_random['system accuracy'])\n",
    "        data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)\n",
    "    error_random_trials.append(error_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "po1kQ2n5F-xs"
   },
   "outputs": [],
   "source": [
    "# confidence selection WITH LCE\n",
    "# this is the exact algorithm in the paper\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def get_least_confident_points(model, data_loader, budget):\n",
    "    '''\n",
    "    based on entropy score get points, can chagnge, but make sure to get max or min accordingly\n",
    "    '''\n",
    "    uncertainty_estimates = []\n",
    "    indices_all = []\n",
    "    for data in data_loader:\n",
    "        images, labels, expert_preds, indices, _ = data\n",
    "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
    "        outputs = model(images)\n",
    "        batch_size = outputs.size()[0]  \n",
    "        for i in range(0, batch_size):\n",
    "            output_i =  outputs.data[i].cpu().numpy()\n",
    "            entropy_i = entropy(output_i)\n",
    "            #entropy_i = 1 - max(output_i)\n",
    "            uncertainty_estimates.append(entropy_i)\n",
    "            indices_all.append(indices[i].item())\n",
    "    indices_all = np.array(indices_all)\n",
    "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
    "    actual_indices = indices_all[top_budget_indices]\n",
    "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
    "    return actual_indices\n",
    "import copy\n",
    "EPOCHS_DEFER = 10\n",
    "error_confidence_trials_LCE = []\n",
    "\n",
    "\n",
    "for trial in range(MAX_TRIALS):\n",
    "    print(f'\\n \\n \\n Trial {trial} \\n \\n \\n ')\n",
    "    # initialize data\n",
    "    all_indices = list(range(len(train_dataset.indices)))\n",
    "    all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "    all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
    "    dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
    "\n",
    "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "    # train expert model on labeled data\n",
    "    model_expert = NetSimple(2, 100, 100, 1000,500).to(device)\n",
    "    run_expert(model_expert, EPOCH_TRAIN, dataLoaderTrainLabeled, dataLoaderTrainLabeled) \n",
    "\n",
    "    data_sizes = []\n",
    "    error_confidence = []\n",
    "    data_sizes.append(INITIAL_SIZE)\n",
    "    # train model to do classification\n",
    "    model_lce = NetSimple(n_dataset + 1, 100, 100, 1000,500).to(device)\n",
    "    run_reject_class(model_lce, EPOCH_TRAIN, dataLoaderTrain, dataLoaderVal)\n",
    "    model_lce_saved = copy.deepcopy(model_lce.state_dict())\n",
    "    \n",
    "    # get expert model predictions on unlabeled data\n",
    "    dataLoaderTrainUnlabeledUnshuffled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "    expert_preds_arr = []\n",
    "    for data in dataLoaderTrainUnlabeledUnshuffled:\n",
    "        images, labels, _, _, _ = data\n",
    "        images = images.to(device)\n",
    "        outputs_exp = model_expert(images)\n",
    "        for i in range(outputs_exp.size()[0]):\n",
    "            #pred_exp = np.argmax(outputs_exp.data[i].cpu().numpy())\n",
    "            pred_exp = outputs_exp.data[i].cpu().numpy()\n",
    "            pred_exp = pred_exp[1]\n",
    "            expert_preds_arr.append(pred_exp)\n",
    "    expert_preds_unlabeled = np.array(expert_preds_arr)\n",
    "    expert_preds_labeled = np.array(Expert.predict (None, torch.FloatTensor(all_data_y[indices_labeled])))\n",
    "    expert_preds_labeled = ( expert_preds_labeled == all_data_y[indices_labeled]) * 1\n",
    "    expert_preds_combined = np.concatenate(( expert_preds_labeled, expert_preds_unlabeled))\n",
    "    # create pseudo-labeled dataset\n",
    "    dataset_train_pseudolabeled = CifarExpertDataset(np.concatenate((all_data_x[indices_labeled] , all_data_x[indices_unlabeled])),\n",
    "                                                        np.concatenate((all_data_y[indices_labeled] , all_data_y[indices_unlabeled])), Expert.predict , [1]*(len(indices_labeled) + len(indices_unlabeled)), None,\n",
    "                                                        expert_preds_combined)\n",
    "    dataLoaderTrainPseudoLabeled = DataLoader(dataset=dataset_train_pseudolabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "    # train model on pseudo-labeled data\n",
    "    run_reject_pseudo(model_lce, 10, Expert.predict, EPOCHS_DEFER, 1, dataLoaderTrainPseudoLabeled, dataLoaderTrainLabeled)\n",
    "    metrics_confidence = metrics_print(model_lce, Expert.predict, n_dataset, dataLoaderTest)\n",
    "    error_confidence.append(metrics_confidence['system accuracy'])\n",
    "    for round in range(MAX_ROUNDS):\n",
    "        model_lce.load_state_dict(model_lce_saved)\n",
    "        # get points where expert model is least confident on\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "        indices_confidence =  random.sample(indices_unlabeled, BATCH_SIZE_AL)#get_least_confident_points(model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
    "        indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "        dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled))\n",
    "        dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled))\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        # train model on labeled data\n",
    "        run_expert(model_expert, EPOCH_TRAIN, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "        # get expert predictions on unlabeled data\n",
    "        dataLoaderTrainUnlabeledUnshuffled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "        expert_preds_arr = []\n",
    "        for data in dataLoaderTrainUnlabeledUnshuffled:\n",
    "            images, labels, _, _, _ = data\n",
    "            images = images.to(device)\n",
    "            outputs_exp = model_expert(images)\n",
    "            for i in range(outputs_exp.size()[0]):\n",
    "                #pred_exp = np.argmax(outputs_exp.data[i].cpu().numpy())\n",
    "                pred_exp = outputs_exp.data[i].cpu().numpy()\n",
    "                pred_exp = pred_exp[1]\n",
    "                expert_preds_arr.append(pred_exp)\n",
    "        expert_preds_unlabeled = np.array(expert_preds_arr)\n",
    "        expert_preds_labeled = np.array(Expert.predict (None, torch.FloatTensor(all_data_y[indices_labeled])))\n",
    "        expert_preds_labeled = ( expert_preds_labeled == all_data_y[indices_labeled]) * 1\n",
    "        expert_preds_combined = np.concatenate(( expert_preds_labeled, expert_preds_unlabeled))\n",
    "        # create pseudo-labeled dataset\n",
    "        \n",
    "        dataset_train_pseudolabeled = CifarExpertDataset(np.concatenate((all_data_x[indices_labeled] , all_data_x[indices_unlabeled])),\n",
    "                                                         np.concatenate((all_data_y[indices_labeled] , all_data_y[indices_unlabeled])), Expert.predict , [1]*(len(indices_labeled) + len(indices_unlabeled))  , None,\n",
    "                                                         expert_preds_combined)\n",
    "        dataLoaderTrainPseudoLabeled = DataLoader(dataset=dataset_train_pseudolabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "        # train model on pseudo labeled data\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        for alpha in [1]:\n",
    "            print(f'alpha {alpha}')\n",
    "            model_lce.load_state_dict(model_lce_saved)\n",
    "            model_dict_alpha = run_reject_pseudo(model_lce, 10, Expert.predict, EPOCHS_DEFER, 1, dataLoaderTrainPseudoLabeled, dataLoaderTest, True, EPOCHS_DEFER-1)\n",
    "            model_lce.load_state_dict(model_dict_alpha)\n",
    "            score = metrics_print(model_lce, Expert.predict, n_dataset, dataLoaderTest)['system accuracy']\n",
    "            if score >= best_score:\n",
    "                best_score =  score\n",
    "                best_model = model_dict_alpha\n",
    "        model_lce.load_state_dict(best_model)\n",
    "\n",
    "        #run_reject(model_lce, 10, Expert.predict, EPOCHS_DEFER, 1, dataLoaderTrainPseudoLabeled, dataLoaderTrainLabeled)\n",
    "        metrics_confidence = metrics_print(model_lce, Expert.predict, n_dataset, dataLoaderTest)\n",
    "        error_confidence.append(metrics_confidence['system accuracy'])\n",
    "        data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)\n",
    "    error_confidence_trials_LCE.append(error_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW0wMpIABppB"
   },
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk7MhFZdUExS"
   },
   "outputs": [],
   "source": [
    "#!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "def get_conf_interval(arr):\n",
    "    alpha_level = 0.4\n",
    "    err  = st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[1]/2  - st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[0]/2 \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "KXSoV9ERUJou",
    "outputId": "33b393cd-4aa8-4f2c-9217-080d17ea7b6a"
   },
   "outputs": [],
   "source": [
    "# uncomment things to plot more\n",
    "\n",
    "#avgs_rand = [np.average([scores_oracle[triall] - scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#stds_rand = [np.std([scores_oracle[triall] -scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
    "avgs_rand = [np.average([error_random_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS + 1)]\n",
    "stds_rand = [np.std([error_random_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS + 1)]\n",
    "plt.errorbar(data_sizes,  avgs_rand, yerr=stds_rand, marker = \"+\",  label=f'Random')\n",
    "'''\n",
    "avgs_rand = [np.average([error_confidence_rejector_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS + 1)]\n",
    "stds_rand = [np.std([error_confidence_rejector_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS + 1)]\n",
    "plt.errorbar(data_sizes,  avgs_rand, yerr=stds_rand, marker = \"+\",  label=f'Rejector')\n",
    "\n",
    "avgs_rand = [np.average([error_confidence_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS+1)]\n",
    "stds_rand = [np.std([error_confidence_trials[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS+1)]\n",
    "plt.errorbar(data_sizes,  avgs_rand, yerr=stds_rand, marker = \"o\",  label=f'Entropy Sampling')\n",
    "'''\n",
    "'''\n",
    "avgs_rand = [np.average([error_confidence_trials_LCE[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS+1)]\n",
    "stds_rand = [np.std([error_confidence_trials_LCE[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(MAX_ROUNDS+1)]\n",
    "plt.errorbar(data_sizes,  avgs_rand, yerr=stds_rand, marker = \"o\",  label=f'Entropy Sampling (Ensemble)')\n",
    "'''\n",
    "\n",
    "#plt.errorbar(data_sizes,  error_confidence_rejector, yerr=[0]*len(error_confidence_rejector), marker = \"+\",  label=f'Rejector Uncertainty')\n",
    "#plt.errorbar(data_sizes,  errors_LCE, yerr=[0]*len(errors_LCE), marker = \"o\",  label=f'LCE random')\n",
    "#plt.errorbar(data_sizes,  errors_teaching, yerr=[0]*len(error_confidence_rejector), marker = \"o\",  label=f'Teaching')\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()   \n",
    "plt.grid()\n",
    "plt.legend(fontsize='large')\n",
    "plt.legend()\n",
    "plt.ylabel('System Accuracy',  fontsize='x-large')\n",
    "plt.xlabel('Acquired data size', fontsize='x-large')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 6\n",
    "fig_size[1] = 4\n",
    "#plt.savefig(\"teaching_complexity_cifar10.pdf\", dpi = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Representations\n",
    "This is the same as above but with linear representation and linear networks instead of training on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning parameters\n",
    "INITIAL_SIZE = 100\n",
    "BATCH_SIZE_AL = 1000\n",
    "MAX_ROUNDS = 10\n",
    "EPOCH_TRAIN = 10\n",
    "MAX_TRIALS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CifarExpertDataset(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices))\n",
    "dataset_val = CifarExpertDataset(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices))\n",
    "dataset_test = CifarExpertDataset(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets))\n",
    "\n",
    "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_repr_dim = 50\n",
    "model = NetSimple(n_dataset + 1, 100, 100, 1000, hidden_repr_dim).to(device)\n",
    "run_reject_class(model, 15, dataLoaderTrain, dataLoaderVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_print_classifier(model, dataLoaderVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize datasets with linear representations\n",
    "dataset_train = CifarExpertDatasetLinear(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices),None, model)\n",
    "dataset_val = CifarExpertDatasetLinear(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices),None, model)\n",
    "dataset_test = CifarExpertDatasetLinear(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets),None,  model)\n",
    "\n",
    "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = list(range(len(train_dataset.indices)))\n",
    "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
    "indices_labeled  = intial_random_set\n",
    "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "\n",
    "\n",
    "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled, model)\n",
    "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, model)\n",
    "\n",
    "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below are re-intialized to work with linear representations\n",
    "Make sure to not run this beforee the above, because it re-defines methods imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expert_confidence(train_loader, model, optimizer, scheduler, epoch):\n",
    "    \"\"\"Train for one epoch on the training set without deferral\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, label, expert_pred, _, _ ) in enumerate(train_loader):\n",
    "        expert_pred = expert_pred.long()\n",
    "        expert_pred = (expert_pred == label) *1\n",
    "        target = expert_pred.to(device)\n",
    "        input = input.to(device)\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        # compute loss\n",
    "        loss = my_CrossEntropyLoss(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1))\n",
    "            \n",
    "\n",
    "\n",
    "def metrics_print_expert(model, data_loader, defer_net = False):\n",
    "    '''\n",
    "    model: model\n",
    "    data_loader: data loader\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, label, expert_pred, _ ,_ = data\n",
    "            expert_pred = expert_pred.long()\n",
    "            expert_pred = (expert_pred == label) *1\n",
    "            images, labels = images.to(device), expert_pred.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs.data, 1) # maybe no .data\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the %d test images: %.3f %%' % (total,\n",
    "        100 * correct / total))\n",
    "\n",
    "def run_expert(model, epochs, train_loader, val_loader):\n",
    "    '''\n",
    "    only train classifier\n",
    "    model: WideResNet model\n",
    "    epochs: number of epochs to train\n",
    "    '''\n",
    "    # get the number of model parameters\n",
    "    print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "\n",
    "\n",
    "    # cosine learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        # train for one epoch\n",
    "        train_expert_confidence(train_loader, model, optimizer, scheduler, epoch)\n",
    "        if epoch % 10 == 0:\n",
    "            metrics_print_expert(model, val_loader)\n",
    "    metrics_print_expert(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_print_2step(net_mod, net_exp, expert_fn, n_classes, loader):\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels, expert_preds, _, images_orig = data\n",
    "            images, labels, expert_preds, images_orig = images.to(device), labels.to(device), expert_preds.to(device), images_orig.to(device)\n",
    "            outputs_mod = net_mod(images_orig)\n",
    "            outputs_exp = net_exp(images)\n",
    "            _, predicted = torch.max(outputs_mod.data, 1)\n",
    "            _, predicted_exp = torch.max(outputs_exp.data, 1)\n",
    "            batch_size = outputs_mod.size()[0]  # batch_size\n",
    "            exp_prediction = expert_fn(images, labels)\n",
    "            for i in range(0, batch_size):\n",
    "                r_score =  outputs_mod.data[i][predicted[i].item()].item()\n",
    "                r_score = outputs_exp.data[i][1].item() - r_score\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                else:\n",
    "                    r = 0\n",
    "                if r == 0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == labels[i]).item()\n",
    "                    correct_sys += (predicted[i] == labels[i]).item()\n",
    "                if r == 1:\n",
    "                    exp += (exp_prediction[i] == labels[i].item())\n",
    "                    correct_sys += (exp_prediction[i] == labels[i].item())\n",
    "                    exp_total += 1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print = {\"coverage\": cov, \"system accuracy\": 100 * correct_sys / real_total,\n",
    "                \"expert accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "                \"classifier accuracy\": 100 * correct / (total + 0.0001)}\n",
    "    return to_print\n",
    "    print(to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_net(nn.Module):\n",
    "    '''\n",
    "    Linear multiclass classifier with unit init\n",
    "    '''\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(Linear_net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(input_dim, out_dim)\n",
    "        torch.nn.init.ones_(self.fc1.weight)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to re-write this to add MAX_TRIALS (run this multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection\n",
    "Intial_random_set = random.sample(all_indices, INITIAL_SIZE)\n",
    "\n",
    "all_indices = list(range(len(train_dataset.indices)))\n",
    "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "indices_labeled  = Intial_random_set\n",
    "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled, model)\n",
    "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, model)\n",
    "\n",
    "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "model_expert = Linear_net(hidden_repr_dim, 2).to(device)\n",
    "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "data_sizes = []\n",
    "error_random = []\n",
    "data_sizes.append(INITIAL_SIZE)\n",
    "metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
    "error_random.append(metrics_random['system accuracy'])\n",
    "for round in range(MAX_ROUNDS):\n",
    "    print(f'\\n \\n Round {round} \\n \\n')\n",
    "    intial_random_set = random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
    "\n",
    "    indices_labeled  = indices_labeled + intial_random_set \n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "    dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
    "    dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
    "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    model_expert = Linear_net(hidden_repr_dim, 2).to(device)\n",
    "\n",
    "    run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "\n",
    "    metrics_random = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
    "    error_random.append(metrics_random['system accuracy'])\n",
    "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence selection\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def get_least_confident_points(model, data_loader, budget):\n",
    "    '''\n",
    "    based on entropy score, can chagnge, but make sure to get max or min accordingly\n",
    "    '''\n",
    "    uncertainty_estimates = []\n",
    "    indices_all = []\n",
    "    for data in data_loader:\n",
    "        images, labels, expert_preds, indices, _ = data\n",
    "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
    "        outputs = model(images)\n",
    "        batch_size = outputs.size()[0]  \n",
    "        for i in range(0, batch_size):\n",
    "            output_i =  outputs.data[i].cpu().numpy()\n",
    "            entropy_i = entropy(output_i)\n",
    "            #entropy_i = 1 - max(output_i)\n",
    "            uncertainty_estimates.append(entropy_i)\n",
    "            indices_all.append(indices[i].item())\n",
    "    indices_all = np.array(indices_all)\n",
    "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
    "    actual_indices = indices_all[top_budget_indices]\n",
    "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
    "    return actual_indices\n",
    "all_indices = list(range(len(train_dataset.indices)))\n",
    "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "indices_labeled  = Intial_random_set\n",
    "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
    "dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
    "    \n",
    "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "model_expert = Linear_net(hidden_repr_dim, 2).to(device)\n",
    "run_expert(model_expert, 10, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "data_sizes = []\n",
    "error_confidence = []\n",
    "data_sizes.append(INITIAL_SIZE)\n",
    "metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
    "error_confidence.append(metrics_confidence['system accuracy'])\n",
    "\n",
    "\n",
    "for round in range(MAX_ROUNDS):\n",
    "    print(f'\\n \\n Round {round} \\n \\n')\n",
    "    indices_confidence = get_least_confident_points(model_expert, dataLoaderTrainUnlabeled, BATCH_SIZE_AL)\n",
    "\n",
    "    indices_labeled  = indices_labeled + intial_random_set \n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "    dataset_train_labeled = CifarExpertDatasetLinear(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), None, model)\n",
    "    dataset_train_unlabeled = CifarExpertDatasetLinear(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), None, model)\n",
    "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=1000, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    \n",
    "    model_expert = Linear_net(hidden_repr_dim, 2).to(device)\n",
    "\n",
    "    run_expert(model_expert, 50, dataLoaderTrainLabeled, dataLoaderTrainLabeled)\n",
    "\n",
    "    metrics_confidence = metrics_print_2step(model, model_expert, Expert.predict, 10, dataLoaderVal)\n",
    "    error_confidence.append(metrics_confidence['system accuracy'])\n",
    "    data_sizes.append((round+1)*BATCH_SIZE_AL + INITIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#avgs_rand = [np.average([scores_oracle[triall] - scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#stds_rand = [np.std([scores_oracle[triall] -scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
    "plt.errorbar(data_sizes,  error_random, yerr=[0]*len(data_sizes), marker = \"+\",  label=f'Random')\n",
    "#plt.errorbar(data_sizes2,  error_confidence[:59], yerr=[0]*len(data_sizes2), marker = \"+\",  label=f'Entropy Sampling')\n",
    "#plt.errorbar(data_sizes,  error_confidence_rejector, yerr=[0]*len(error_confidence_rejector), marker = \"+\",  label=f'Rejector Uncertainty')\n",
    "#plt.errorbar(data_sizes,  errors_LCE, yerr=[0]*len(errors_LCE), marker = \"o\",  label=f'LCE random')\n",
    "#plt.errorbar(data_sizes,  errors_teaching, yerr=[0]*len(error_confidence_rejector), marker = \"o\",  label=f'Teaching')\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()   \n",
    "plt.grid()\n",
    "plt.legend(fontsize='large')\n",
    "plt.legend()\n",
    "plt.ylabel('System Accuracy',  fontsize='x-large')\n",
    "plt.xlabel('Acquired data size', fontsize='x-large')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 6\n",
    "fig_size[1] = 4\n",
    "#plt.savefig(\"teaching_complexity_cifar10.pdf\", dpi = 1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "a7Aympk-qwGu",
    "iYllTn0F2iDg",
    "iqf_r99A1OcX",
    "s8bHnx2qbN2o"
   ],
   "name": "cifar_active_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
